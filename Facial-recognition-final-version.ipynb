{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0113e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kfp==1.4.0 in ./.local/lib/python3.8/site-packages (from -r requirement.txt (line 1)) (1.4.0)\n",
      "Requirement already satisfied: numpy in ./.local/lib/python3.8/site-packages (from -r requirement.txt (line 2)) (1.22.4)\n",
      "Requirement already satisfied: sklearn in ./.local/lib/python3.8/site-packages (from -r requirement.txt (line 3)) (0.0)\n",
      "Requirement already satisfied: requests-toolbelt>=0.8.0 in /opt/conda/lib/python3.8/site-packages (from kfp==1.4.0->-r requirement.txt (line 1)) (0.9.1)\n",
      "Requirement already satisfied: google-auth>=1.6.1 in /opt/conda/lib/python3.8/site-packages (from kfp==1.4.0->-r requirement.txt (line 1)) (1.28.1)\n",
      "Requirement already satisfied: google-cloud-storage>=1.13.0 in /opt/conda/lib/python3.8/site-packages (from kfp==1.4.0->-r requirement.txt (line 1)) (1.37.1)\n",
      "Requirement already satisfied: cloudpickle in /opt/conda/lib/python3.8/site-packages (from kfp==1.4.0->-r requirement.txt (line 1)) (1.6.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from kfp==1.4.0->-r requirement.txt (line 1)) (7.1.2)\n",
      "Requirement already satisfied: fire>=0.3.1 in ./.local/lib/python3.8/site-packages (from kfp==1.4.0->-r requirement.txt (line 1)) (0.4.0)\n",
      "Requirement already satisfied: kubernetes<12.0.0,>=8.0.0 in /opt/conda/lib/python3.8/site-packages (from kfp==1.4.0->-r requirement.txt (line 1)) (10.0.1)\n",
      "Requirement already satisfied: docstring-parser>=0.7.3 in ./.local/lib/python3.8/site-packages (from kfp==1.4.0->-r requirement.txt (line 1)) (0.13)\n",
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.8/site-packages (from kfp==1.4.0->-r requirement.txt (line 1)) (0.8.9)\n",
      "Requirement already satisfied: strip-hints in /opt/conda/lib/python3.8/site-packages (from kfp==1.4.0->-r requirement.txt (line 1)) (0.1.9)\n",
      "Requirement already satisfied: kfp-server-api<2.0.0,>=1.1.2 in ./.local/lib/python3.8/site-packages (from kfp==1.4.0->-r requirement.txt (line 1)) (1.7.1)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.8/site-packages (from kfp==1.4.0->-r requirement.txt (line 1)) (5.4.1)\n",
      "Requirement already satisfied: kfp-pipeline-spec<0.2.0,>=0.1.0 in ./.local/lib/python3.8/site-packages (from kfp==1.4.0->-r requirement.txt (line 1)) (0.1.13)\n",
      "Requirement already satisfied: Deprecated in /opt/conda/lib/python3.8/site-packages (from kfp==1.4.0->-r requirement.txt (line 1)) (1.2.12)\n",
      "Requirement already satisfied: jsonschema>=3.0.1 in /opt/conda/lib/python3.8/site-packages (from kfp==1.4.0->-r requirement.txt (line 1)) (3.2.0)\n",
      "Requirement already satisfied: termcolor in ./.local/lib/python3.8/site-packages (from fire>=0.3.1->kfp==1.4.0->-r requirement.txt (line 1)) (1.1.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from fire>=0.3.1->kfp==1.4.0->-r requirement.txt (line 1)) (1.15.0)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.8/site-packages (from google-auth>=1.6.1->kfp==1.4.0->-r requirement.txt (line 1)) (49.6.0.post20210108)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.8/site-packages (from google-auth>=1.6.1->kfp==1.4.0->-r requirement.txt (line 1)) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from google-auth>=1.6.1->kfp==1.4.0->-r requirement.txt (line 1)) (4.2.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.8/site-packages (from google-auth>=1.6.1->kfp==1.4.0->-r requirement.txt (line 1)) (0.2.8)\n",
      "Requirement already satisfied: google-cloud-core<2.0dev,>=1.4.1 in /opt/conda/lib/python3.8/site-packages (from google-cloud-storage>=1.13.0->kfp==1.4.0->-r requirement.txt (line 1)) (1.6.0)\n",
      "Requirement already satisfied: google-resumable-media<2.0dev,>=1.2.0 in /opt/conda/lib/python3.8/site-packages (from google-cloud-storage>=1.13.0->kfp==1.4.0->-r requirement.txt (line 1)) (1.2.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.8/site-packages (from google-cloud-storage>=1.13.0->kfp==1.4.0->-r requirement.txt (line 1)) (2.25.1)\n",
      "Requirement already satisfied: google-api-core<2.0.0dev,>=1.21.0 in /opt/conda/lib/python3.8/site-packages (from google-cloud-core<2.0dev,>=1.4.1->google-cloud-storage>=1.13.0->kfp==1.4.0->-r requirement.txt (line 1)) (1.26.3)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.8/site-packages (from google-api-core<2.0.0dev,>=1.21.0->google-cloud-core<2.0dev,>=1.4.1->google-cloud-storage>=1.13.0->kfp==1.4.0->-r requirement.txt (line 1)) (20.9)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /opt/conda/lib/python3.8/site-packages (from google-api-core<2.0.0dev,>=1.21.0->google-cloud-core<2.0dev,>=1.4.1->google-cloud-storage>=1.13.0->kfp==1.4.0->-r requirement.txt (line 1)) (3.15.7)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /opt/conda/lib/python3.8/site-packages (from google-api-core<2.0.0dev,>=1.21.0->google-cloud-core<2.0dev,>=1.4.1->google-cloud-storage>=1.13.0->kfp==1.4.0->-r requirement.txt (line 1)) (1.53.0)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.8/site-packages (from google-api-core<2.0.0dev,>=1.21.0->google-cloud-core<2.0dev,>=1.4.1->google-cloud-storage>=1.13.0->kfp==1.4.0->-r requirement.txt (line 1)) (2021.1)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.8/site-packages (from google-resumable-media<2.0dev,>=1.2.0->google-cloud-storage>=1.13.0->kfp==1.4.0->-r requirement.txt (line 1)) (1.1.2)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from google-crc32c<2.0dev,>=1.0->google-resumable-media<2.0dev,>=1.2.0->google-cloud-storage>=1.13.0->kfp==1.4.0->-r requirement.txt (line 1)) (1.14.5)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.8/site-packages (from cffi>=1.0.0->google-crc32c<2.0dev,>=1.0->google-resumable-media<2.0dev,>=1.2.0->google-cloud-storage>=1.13.0->kfp==1.4.0->-r requirement.txt (line 1)) (2.20)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema>=3.0.1->kfp==1.4.0->-r requirement.txt (line 1)) (0.17.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema>=3.0.1->kfp==1.4.0->-r requirement.txt (line 1)) (20.3.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.8/site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp==1.4.0->-r requirement.txt (line 1)) (2020.12.5)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.8/site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp==1.4.0->-r requirement.txt (line 1)) (2.8.1)\n",
      "Requirement already satisfied: urllib3>=1.15 in /opt/conda/lib/python3.8/site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp==1.4.0->-r requirement.txt (line 1)) (1.26.4)\n",
      "Requirement already satisfied: requests-oauthlib in /opt/conda/lib/python3.8/site-packages (from kubernetes<12.0.0,>=8.0.0->kfp==1.4.0->-r requirement.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/conda/lib/python3.8/site-packages (from kubernetes<12.0.0,>=8.0.0->kfp==1.4.0->-r requirement.txt (line 1)) (0.58.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=14.3->google-api-core<2.0.0dev,>=1.21.0->google-cloud-core<2.0dev,>=1.4.1->google-cloud-storage>=1.13.0->kfp==1.4.0->-r requirement.txt (line 1)) (2.4.7)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.6.1->kfp==1.4.0->-r requirement.txt (line 1)) (0.4.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage>=1.13.0->kfp==1.4.0->-r requirement.txt (line 1)) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage>=1.13.0->kfp==1.4.0->-r requirement.txt (line 1)) (4.0.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.8/site-packages (from sklearn->-r requirement.txt (line 3)) (0.24.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.8/site-packages (from Deprecated->kfp==1.4.0->-r requirement.txt (line 1)) (1.12.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.8/site-packages (from requests-oauthlib->kubernetes<12.0.0,>=8.0.0->kfp==1.4.0->-r requirement.txt (line 1)) (3.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.8/site-packages (from scikit-learn->sklearn->-r requirement.txt (line 3)) (1.6.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn->sklearn->-r requirement.txt (line 3)) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.8/site-packages (from scikit-learn->sklearn->-r requirement.txt (line 3)) (1.0.1)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.8/site-packages (from strip-hints->kfp==1.4.0->-r requirement.txt (line 1)) (0.36.2)\n"
     ]
    }
   ],
   "source": [
    "with open(\"requirement.txt\", \"w\") as f:\n",
    "    f.write(\"kfp==1.4.0\\n\")\n",
    "    f.write(\"numpy\\n\")\n",
    "    f.write(\"sklearn\\n\")\n",
    "!pip install -r requirement.txt  --upgrade --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3beb88f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "import numpy\n",
    "def load_data(log_folder:str)->NamedTuple('Outputs', [('runtime_string',str)]):\n",
    "    import pickle\n",
    "    from numpy import savez_compressed, asarray, load, expand_dims\n",
    "    import numpy as np\n",
    "    from PIL import Image\n",
    "    from os.path import isdir\n",
    "    from os import listdir\n",
    "    import os\n",
    "    import time\n",
    "    import datetime\n",
    "    import warnings\n",
    "    #import detect_face\n",
    "    import tensorflow\n",
    "    from mtcnn_cv2 import MTCNN\n",
    "    import sys\n",
    "    print(\"import done...\")\n",
    "    print(sys.version)\n",
    "    sys.path.append(\"./\")\n",
    "    \n",
    "    dataset_train = os.path.join(\"train/\")\n",
    "    dataset_val = os.path.join(\"val/\")\n",
    "\n",
    "    def extract_face(filename, required_size=(160, 160)):\n",
    "        # load image from file\n",
    "        image = Image.open(filename)\n",
    "        # convert to RGB, if needed\n",
    "        image = image.convert('RGB')\n",
    "        # convert to array\n",
    "        pixels = asarray(image)\n",
    "        # create the detector, using default weights\n",
    "        detector = MTCNN()\n",
    "        # detect faces in the image\n",
    "        results = detector.detect_faces(pixels)\n",
    "        print(results)\n",
    "        if len(results) != 0:\n",
    "            # extract the bounding box from the first face\n",
    "            x1, y1, width, height = results[0]['box']\n",
    "            # bug fix\n",
    "            x1, y1 = abs(x1), abs(y1)\n",
    "            x2, y2 = x1 + width, y1 + height\n",
    "            # extract the face\n",
    "            face = pixels[y1:y2, x1:x2]\n",
    "            # resize pixels to the model size\n",
    "            image = Image.fromarray(face)\n",
    "            image = image.resize(required_size)\n",
    "            face_array = asarray(image)\n",
    "            \n",
    "        else:\n",
    "\n",
    "            pass\n",
    "            \n",
    "\n",
    "        return face_array\n",
    "    \n",
    "    def load_dataset(directory):\n",
    "\n",
    "        X = []\n",
    "        y = []\n",
    "        # enumerate all folders named with class labels\n",
    "        for subdir in listdir(directory):\n",
    "            path = directory + subdir + '/'\n",
    "            # skip any files that might be in the dir\n",
    "            if not isdir(path):\n",
    "                continue\n",
    "            # load all faces in the subdirectory\n",
    "            faces = load_faces(path)\n",
    "            # create labels\n",
    "            labels = [subdir for _ in range(len(faces))]\n",
    "            print(\"loaded {} examples for class: {}\".format(len(faces), subdir))\n",
    "            X.extend(faces)\n",
    "            y.extend(labels)\n",
    "\n",
    "        return asarray(X), asarray(y)\n",
    "    \n",
    "    def load_faces(directory):\n",
    "\n",
    "        faces = []\n",
    "\n",
    "        for filename in listdir(directory):\n",
    "            \n",
    "            path = directory + filename\n",
    "            try:\n",
    "                face = extract_face(path)\n",
    "            \n",
    "            except:\n",
    "                print(\"Wrong image:\", filename)\n",
    "                continue\n",
    "            faces.append(face)\n",
    "            \n",
    "        return faces\n",
    "    \n",
    "    \n",
    "    start_time = time.time()\n",
    "    trainX, trainy = load_dataset(dataset_train)\n",
    "    print(\"Training data set loaded\")\n",
    "\n",
    "    testX, testy = load_dataset(dataset_val)  # load test dataset\n",
    "    print(\"Testing data set loaded\")\n",
    "\n",
    "    # save arrays to one file in compressed format\n",
    "    savez_compressed(\"faces_data\", trainX, trainy, testX, testy)\n",
    "    print(\"Load dataset complete....\")\n",
    "    end_time = time.time()\n",
    "\n",
    "    runtime = (end_time - start_time)/60\n",
    "    print(\"Program time is :\", runtime)\n",
    "    runtime_string = str(runtime)\n",
    "\n",
    "    return[runtime_string]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8e1356c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "import numpy\n",
    "def convert_to_triplet(runtime_string:str)->NamedTuple('Outputs', [('conv_time',str)]):\n",
    "    import time\n",
    "    import numpy as np\n",
    "    import random\n",
    "    import tensorflow as tf\n",
    "    import sys\n",
    "    import os\n",
    "    from tensorflow.keras import backend as K\n",
    "    from itertools import permutations\n",
    "    from tqdm import tqdm\n",
    "    print(sys.version)\n",
    "    sys.path.append(\"./\")\n",
    "    sys.path.append(\"/persist-log\")\n",
    "    from config import img_size, channel\n",
    "    from inception_resnet_v1 import InceptionResNetV1\n",
    "    from sklearn.manifold import TSNE\n",
    "    print(\"import done...\")\n",
    "\n",
    "    \n",
    "    \n",
    "    def generate_triplet_set(x, y, drop_size=0.1, ap_batch=10, n_batch=10, *args, **kwargs):\n",
    "        data_xy = tuple([x, y])\n",
    "        data_size = 1 - drop_size\n",
    "        triplet_train_pairs = []\n",
    "        triplet_test_pairs = []\n",
    "\n",
    "        for data_class in tqdm(sorted(set(data_xy[1]))):\n",
    "\n",
    "            same_class_idx = np.where((data_xy[1] == data_class))[0]\n",
    "            diff_class_idx = np.where(data_xy[1] != data_class)[0]\n",
    "            # Generating Anchor-Positive pairs\n",
    "            A_P_pairs = random.sample(\n",
    "                list(permutations(same_class_idx, 2)), k=ap_batch)\n",
    "\n",
    "            li = list(range(100))\n",
    "            n = ap_batch\n",
    "            #Neg_idx = random.sample(li, n if len(li) > n else len(li))\n",
    "            Neg_idx = random.sample(list(diff_class_idx), k=n_batch)\n",
    "            # train set\n",
    "            A_P_len = len(A_P_pairs)\n",
    "            Neg_len = len(Neg_idx)\n",
    "            for ap in A_P_pairs[:int(A_P_len * data_size)]:\n",
    "                Anchor = data_xy[0][ap[0]]\n",
    "                Positive = data_xy[0][ap[1]]\n",
    "                for n in Neg_idx:\n",
    "                    Negative = data_xy[0][n]\n",
    "                    triplet_train_pairs.append([Anchor, Positive, Negative])\n",
    "\n",
    "            # test set\n",
    "            for ap in A_P_pairs[int(A_P_len * data_size):]:\n",
    "                Anchor = data_xy[0][ap[0]]\n",
    "                Positive = data_xy[0][ap[1]]\n",
    "                for n in Neg_idx:\n",
    "                    Negative = data_xy[0][n]\n",
    "                    triplet_test_pairs.append([Anchor, Positive, Negative])\n",
    "\n",
    "        return np.array(triplet_train_pairs), np.array(triplet_test_pairs)\n",
    "    \n",
    "    conv_time_start = time.time()\n",
    "    tf.compat.v1.disable_eager_execution()\n",
    "    K.clear_session()\n",
    "    faces_data_dir = os.path.join(\"faces_data_new_data.npz\")\n",
    "    data = np.load(faces_data_dir)\n",
    "    x_train, y_train = data['arr_0'], data['arr_1']\n",
    "    x_train = x_train.reshape((-1, img_size, img_size))\n",
    "    print(\"[Train] image:{}, label:{}\".format(x_train.shape, y_train.shape))\n",
    "    x_train_flat = x_train.reshape(-1, (img_size ** 2) * channel)\n",
    "    tsne = TSNE()\n",
    "    train_tsne_embeds = tsne.fit_transform(x_train_flat[:3500])\n",
    "    X_train, X_test = generate_triplet_set(\n",
    "        x_train, y_train, ap_pairs=60, an_pairs=60, testsize=0.2)\n",
    "    print(X_train.shape, X_test.shape)\n",
    "    np.savez_compressed('triplet_data.npz', X_train, X_test)\n",
    "    print(\"susscess\")\n",
    "    conv_time_end = time.time()\n",
    "    conv_time = (conv_time_end-conv_time_start)/60\n",
    "    conv_time = str(conv_time)\n",
    "    return[conv_time]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d4bc4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Distributed_training_work1(conv_time:str)->NamedTuple('Outputs',[('train_time_str1',str)]):\n",
    "    import numpy as np\n",
    "    import sys\n",
    "    import time\n",
    "    import tensorflow as tf\n",
    "    import json\n",
    "    import os\n",
    "    sys.path.append(\"./\")\n",
    "    sys.path.append(\"/persist-log\")\n",
    "    sys.path.append(\"/configfile\")\n",
    "    from config import img_size, channel, faces_data_dir, FREEZE_LAYERS, classify, facenet_weight_path\n",
    "    from inception_resnet_v1 import InceptionResNetV1\n",
    "    from itertools import permutations\n",
    "    from tqdm import tqdm\n",
    "    from tensorflow.keras import backend as K\n",
    "    from sklearn.manifold import TSNE\n",
    "    #load data from pvc in the container\n",
    "    data = np.load('triplet-data.npz')\n",
    "    X_train, X_test = data['arr_0'], data['arr_1']\n",
    "    \n",
    "    train_time_start = time.time()\n",
    "    def training_model(in_shape,freeze_layers,weights_path):\n",
    "\n",
    "        def create_base_network(in_dims,freeze_layers,weights_path):\n",
    "            model = InceptionResNetV1(input_shape=in_dims, weights_path=weights_path)\n",
    "            print('layer length: ', len(model.layers))\n",
    "            for layer in model.layers[:freeze_layers]:\n",
    "                layer.trainable = False\n",
    "            for layer in model.layers[freeze_layers:]:\n",
    "                layer.trainable = True\n",
    "            return model\n",
    "        \n",
    "        def triplet_loss(y_true,y_pred,alpha=0.4):\n",
    "            total_lenght = y_pred.shape.as_list()[-1]\n",
    "            anchor = y_pred[:, 0:int(total_lenght * 1 / 3)]\n",
    "            positive = y_pred[:, int(total_lenght * 1 / 3):int(total_lenght * 2 / 3)]\n",
    "            negative = y_pred[:, int(total_lenght * 2 / 3):int(total_lenght * 3 / 3)]\n",
    "            # distance between the anchor and the positive\n",
    "            pos_dist = K.sum(K.square(anchor - positive), axis=1)\n",
    "            # distance between the anchor and the negative\n",
    "            neg_dist = K.sum(K.square(anchor - negative), axis=1)\n",
    "            # compute loss\n",
    "            basic_loss = pos_dist - neg_dist + alpha\n",
    "            loss = K.maximum(basic_loss, 0.0)\n",
    "            return loss\n",
    "        # define triplet input layers\n",
    "        anchor_input = tf.keras.layers.Input(in_shape, name='anchor_input')\n",
    "        positive_input = tf.keras.layers.Input(in_shape, name='positive_input')\n",
    "        negative_input = tf.keras.layers.Input(in_shape, name='negative_input')\n",
    "        Shared_DNN = create_base_network(in_shape, freeze_layers, weights_path)\n",
    "        # Shared_DNN.summary()\n",
    "        # encoded inputs\n",
    "        encoded_anchor = Shared_DNN(anchor_input)\n",
    "        encoded_positive = Shared_DNN(positive_input)\n",
    "        encoded_negative = Shared_DNN(negative_input)\n",
    "        # output\n",
    "        merged_vector = tf.keras.layers.concatenate([encoded_anchor, encoded_positive, encoded_negative],axis=-1,name='merged_layer')\n",
    "        model = tf.keras.Model(inputs=[anchor_input, positive_input, negative_input], outputs=merged_vector)\n",
    "        model.compile(\n",
    "            optimizer=adam_optim,\n",
    "            loss=triplet_loss,\n",
    "        )\n",
    "        return model\n",
    "    \n",
    "    os.environ['TF_CONFIG'] = json.dumps({'cluster': {'worker': [\"pipeline-worker-0:3001\",\"pipeline-worker-1:3001\",\"pipeline-worker-2:3001\"]},'task': {'type': 'worker', 'index': 0}})\n",
    "    #os.environ['TF_CONFIG'] = json.dumps({'cluster': {'worker': [\"pipeline-worker-1:3000\",\"pipeline-worker-2:3000\",\"pipeline-worker-3:3000\"]},'task': {'type': 'worker', 'index': 0}})\n",
    "    #os.environ['TF_CONFIG'] = json.dumps({'cluster': {'worker': [\"pipeline-worker-0:3001\"]},'task': {'type': 'worker', 'index': 0}})\n",
    "\n",
    "\n",
    "    strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy(\n",
    "        tf.distribute.experimental.CollectiveCommunication.RING)\n",
    "    NUM_WORKERS = strategy.num_replicas_in_sync\n",
    "    print('=================\\r\\nWorkers: ' + str(NUM_WORKERS) + '\\r\\n=================\\r\\n')\n",
    "    #learn_rate = 0.02 + NUM_WORKERS * 2\n",
    "    #learn_rate = 0.5 + NUM_WORKERS * 8  10mins loss 88  descrease\n",
    "    #learn_rate = 5 + NUM_WORKERS * 15\n",
    "    learn_rate = 0.00001 + NUM_WORKERS * 0.0000016\n",
    "    adam_optim = tf.keras.optimizers.Adam(lr=learn_rate)\n",
    "    batch_size = 32* NUM_WORKERS\n",
    "    model_path='/persist-log/test_model_0523.h5'\n",
    "    print(model_path)\n",
    "    callbacks = [tf.keras.callbacks.ModelCheckpoint(model_path, save_weights_only=True, verbose=1)]\n",
    "    #X_train=np.array(X_train)\n",
    "    #print(type(X_train))\n",
    "    with strategy.scope():\n",
    "        Anchor = X_train[:, 0, :].reshape(-1, img_size, img_size, channel)\n",
    "        Positive = X_train[:, 1, :].reshape(-1, img_size, img_size, channel)\n",
    "        Negative = X_train[:, 2, :].reshape(-1, img_size, img_size, channel)\n",
    "        Y_dummy = np.empty(Anchor.shape[0])\n",
    "        model = training_model((img_size, img_size, channel), FREEZE_LAYERS, facenet_weight_path)\n",
    "        \n",
    "    model.fit(x=[Anchor, Positive, Negative],\n",
    "        y=Y_dummy,\n",
    "        # Anchor_test = X_test[:, 0, :].reshape(-1, img_size, img_size, channel)\n",
    "        # Positive_test = X_test[:, 1, :].reshape(-1, img_size, img_size, channel)\n",
    "        # Negative_test = X_test[:, 2, :].reshape(-1, img_size, img_size, channel)\n",
    "        # Y_dummy = np.empty(Anchor.shape[0])\n",
    "        # Y_dummy2 = np.empty((Anchor_test.shape[0], 1))\n",
    "        # validation_data=([Anchor_test,Positive_test,Negative_test],Y_dummy2),\n",
    "        # validation_split=0.2,\n",
    "        batch_size=batch_size,  # old setting: 32\n",
    "        # steps_per_epoch=(X_train.shape[0] // batch_size) + 1,\n",
    "        epochs=10,#-------------------------------------------------------epoch\n",
    "        callbacks=callbacks\n",
    "        )  \n",
    "    \n",
    "    \n",
    "    train_time_end = time.time()\n",
    "    train_time = (train_time_end - train_time_start)/60\n",
    "    train_time_str1 = str(train_time)\n",
    "    \n",
    "    print('execution time = ',train_time_str1)\n",
    "    return [train_time_str1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c43c8339",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Distributed_training_work2(conv_time:str)->NamedTuple('Outputs',[('train_time_str2',str)]):\n",
    "    import numpy as np\n",
    "    import sys\n",
    "    import time\n",
    "    import tensorflow as tf\n",
    "    import json\n",
    "    import os\n",
    "    sys.path.append(\"./\")\n",
    "    sys.path.append(\"/persist-log\")\n",
    "    sys.path.append(\"/configfile\")\n",
    "    from config import img_size, channel, faces_data_dir, FREEZE_LAYERS, classify, facenet_weight_path\n",
    "    from inception_resnet_v1 import InceptionResNetV1\n",
    "    from itertools import permutations\n",
    "    from tqdm import tqdm\n",
    "    from tensorflow.keras import backend as K\n",
    "    from sklearn.manifold import TSNE\n",
    "    #load data from pvc in the container\n",
    "    data = np.load('triplet-data.npz')\n",
    "    X_train, X_test = data['arr_0'], data['arr_1']\n",
    "    \n",
    "    train_time_start = time.time()\n",
    "    def training_model(in_shape,freeze_layers,weights_path):\n",
    "\n",
    "        def create_base_network(in_dims,freeze_layers,weights_path):\n",
    "            model = InceptionResNetV1(input_shape=in_dims, weights_path=weights_path)\n",
    "            print('layer length: ', len(model.layers))\n",
    "            for layer in model.layers[:freeze_layers]:\n",
    "                layer.trainable = False\n",
    "            for layer in model.layers[freeze_layers:]:\n",
    "                layer.trainable = True\n",
    "            return model\n",
    "        \n",
    "        def triplet_loss(y_true,y_pred,alpha=0.4):\n",
    "            total_lenght = y_pred.shape.as_list()[-1]\n",
    "            anchor = y_pred[:, 0:int(total_lenght * 1 / 3)]\n",
    "            positive = y_pred[:, int(total_lenght * 1 / 3):int(total_lenght * 2 / 3)]\n",
    "            negative = y_pred[:, int(total_lenght * 2 / 3):int(total_lenght * 3 / 3)]\n",
    "            # distance between the anchor and the positive\n",
    "            pos_dist = K.sum(K.square(anchor - positive), axis=1)\n",
    "            # distance between the anchor and the negative\n",
    "            neg_dist = K.sum(K.square(anchor - negative), axis=1)\n",
    "            # compute loss\n",
    "            basic_loss = pos_dist - neg_dist + alpha\n",
    "            loss = K.maximum(basic_loss, 0.0)\n",
    "            return loss\n",
    "        # define triplet input layers\n",
    "        anchor_input = tf.keras.layers.Input(in_shape, name='anchor_input')\n",
    "        positive_input = tf.keras.layers.Input(in_shape, name='positive_input')\n",
    "        negative_input = tf.keras.layers.Input(in_shape, name='negative_input')\n",
    "        Shared_DNN = create_base_network(in_shape, freeze_layers, weights_path)\n",
    "        # Shared_DNN.summary()\n",
    "        # encoded inputs\n",
    "        encoded_anchor = Shared_DNN(anchor_input)\n",
    "        encoded_positive = Shared_DNN(positive_input)\n",
    "        encoded_negative = Shared_DNN(negative_input)\n",
    "        # output\n",
    "        merged_vector = tf.keras.layers.concatenate([encoded_anchor, encoded_positive, encoded_negative],axis=-1,name='merged_layer')\n",
    "        model = tf.keras.Model(inputs=[anchor_input, positive_input, negative_input], outputs=merged_vector)\n",
    "        model.compile(\n",
    "            optimizer=adam_optim,\n",
    "            loss=triplet_loss,\n",
    "        )\n",
    "        return model\n",
    "    \n",
    "    os.environ['TF_CONFIG'] = json.dumps({'cluster': {'worker': [\"pipeline-worker-0:3001\",\"pipeline-worker-1:3001\",\"pipeline-worker-2:3001\"]},'task': {'type': 'worker', 'index': 1}})\n",
    "    #os.environ['TF_CONFIG'] = json.dumps({'cluster': {'worker': [\"pipeline-worker-1:3000\",\"pipeline-worker-2:3000\",\"pipeline-worker-3:3000\"]},'task': {'type': 'worker', 'index': 1}})\n",
    "    #os.environ['TF_CONFIG'] = json.dumps({'cluster': {'worker': [\"pipeline-worker-1:3000\"]},'task': {'type': 'worker', 'index': 0}})\n",
    "\n",
    "\n",
    "    strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy(\n",
    "        tf.distribute.experimental.CollectiveCommunication.RING)\n",
    "    NUM_WORKERS = strategy.num_replicas_in_sync\n",
    "    print('=================\\r\\nWorkers: ' + str(NUM_WORKERS) + '\\r\\n=================\\r\\n')\n",
    "    #learn_rate = 0.02 + NUM_WORKERS * 2\n",
    "    #learn_rate = 0.5 + NUM_WORKERS * 8\n",
    "    #learn_rate = 5 + NUM_WORKERS * 15\n",
    "    learn_rate = 0.00001 + NUM_WORKERS * 0.0000016\n",
    "    #learn_rate = 20 + NUM_WORKERS * 8\n",
    "    adam_optim = tf.keras.optimizers.Adam(lr=learn_rate)\n",
    "    batch_size = 32* NUM_WORKERS\n",
    "    model_path='/persist-log/test_model_0523.h5'\n",
    "    print(model_path)\n",
    "    callbacks = [tf.keras.callbacks.ModelCheckpoint(model_path, save_weights_only=True, verbose=1)]\n",
    "    #X_train=np.array(X_train)\n",
    "    #print(type(X_train))\n",
    "    with strategy.scope():\n",
    "        Anchor = X_train[:, 0, :].reshape(-1, img_size, img_size, channel)\n",
    "        Positive = X_train[:, 1, :].reshape(-1, img_size, img_size, channel)\n",
    "        Negative = X_train[:, 2, :].reshape(-1, img_size, img_size, channel)\n",
    "        Y_dummy = np.empty(Anchor.shape[0])\n",
    "        model = training_model((img_size, img_size, channel), FREEZE_LAYERS, facenet_weight_path)\n",
    "        \n",
    "    model.fit(x=[Anchor, Positive, Negative],\n",
    "        y=Y_dummy,\n",
    "        # Anchor_test = X_test[:, 0, :].reshape(-1, img_size, img_size, channel)\n",
    "        # Positive_test = X_test[:, 1, :].reshape(-1, img_size, img_size, channel)\n",
    "        # Negative_test = X_test[:, 2, :].reshape(-1, img_size, img_size, channel)\n",
    "        # Y_dummy = np.empty(Anchor.shape[0])\n",
    "        # Y_dummy2 = np.empty((Anchor_test.shape[0], 1))\n",
    "        # validation_data=([Anchor_test,Positive_test,Negative_test],Y_dummy2),\n",
    "        # validation_split=0.2,\n",
    "        batch_size=batch_size,  # old setting: 32\n",
    "        # steps_per_epoch=(X_train.shape[0] // batch_size) + 1,\n",
    "        epochs=10,#-------------------------------------------------------epoch\n",
    "        callbacks=callbacks\n",
    "        )  \n",
    "    \n",
    "    \n",
    "    train_time_end = time.time()\n",
    "    train_time = (train_time_end - train_time_start)/60\n",
    "    train_time_str2 = str(train_time)\n",
    "    \n",
    "    print('execution time = ',train_time_str2)\n",
    "    return [train_time_str2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5211ceff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Distributed_training_work3(conv_time:str)->NamedTuple('Outputs',[('train_time_str3',str)]):\n",
    "    import numpy as np\n",
    "    import sys\n",
    "    import time\n",
    "    import tensorflow as tf\n",
    "    import json\n",
    "    import os\n",
    "    sys.path.append(\"./\")\n",
    "    sys.path.append(\"/persist-log\")\n",
    "    sys.path.append(\"/configfile\")\n",
    "    from config import img_size, channel, faces_data_dir, FREEZE_LAYERS, classify, facenet_weight_path\n",
    "    from inception_resnet_v1 import InceptionResNetV1\n",
    "    from itertools import permutations\n",
    "    from tqdm import tqdm\n",
    "    from tensorflow.keras import backend as K\n",
    "    from sklearn.manifold import TSNE\n",
    "    #load data from pvc in the container\n",
    "    data = np.load('triplet-data.npz')\n",
    "    X_train, X_test = data['arr_0'], data['arr_1']\n",
    "    \n",
    "    train_time_start = time.time()\n",
    "    def training_model(in_shape,freeze_layers,weights_path):\n",
    "\n",
    "        def create_base_network(in_dims,freeze_layers,weights_path):\n",
    "            model = InceptionResNetV1(input_shape=in_dims, weights_path=weights_path)\n",
    "            print('layer length: ', len(model.layers))\n",
    "            for layer in model.layers[:freeze_layers]:\n",
    "                layer.trainable = False\n",
    "            for layer in model.layers[freeze_layers:]:\n",
    "                layer.trainable = True\n",
    "            return model\n",
    "        \n",
    "        def triplet_loss(y_true,y_pred,alpha=0.4):\n",
    "            total_lenght = y_pred.shape.as_list()[-1]\n",
    "            anchor = y_pred[:, 0:int(total_lenght * 1 / 3)]\n",
    "            positive = y_pred[:, int(total_lenght * 1 / 3):int(total_lenght * 2 / 3)]\n",
    "            negative = y_pred[:, int(total_lenght * 2 / 3):int(total_lenght * 3 / 3)]\n",
    "            # distance between the anchor and the positive\n",
    "            pos_dist = K.sum(K.square(anchor - positive), axis=1)\n",
    "            # distance between the anchor and the negative\n",
    "            neg_dist = K.sum(K.square(anchor - negative), axis=1)\n",
    "            # compute loss\n",
    "            basic_loss = pos_dist - neg_dist + alpha\n",
    "            loss = K.maximum(basic_loss, 0.0)\n",
    "            return loss\n",
    "        # define triplet input layers\n",
    "        anchor_input = tf.keras.layers.Input(in_shape, name='anchor_input')\n",
    "        positive_input = tf.keras.layers.Input(in_shape, name='positive_input')\n",
    "        negative_input = tf.keras.layers.Input(in_shape, name='negative_input')\n",
    "        Shared_DNN = create_base_network(in_shape, freeze_layers, weights_path)\n",
    "        # Shared_DNN.summary()\n",
    "        # encoded inputs\n",
    "        encoded_anchor = Shared_DNN(anchor_input)\n",
    "        encoded_positive = Shared_DNN(positive_input)\n",
    "        encoded_negative = Shared_DNN(negative_input)\n",
    "        # output\n",
    "        merged_vector = tf.keras.layers.concatenate([encoded_anchor, encoded_positive, encoded_negative],axis=-1,name='merged_layer')\n",
    "        model = tf.keras.Model(inputs=[anchor_input, positive_input, negative_input], outputs=merged_vector)\n",
    "        model.compile(\n",
    "            optimizer=adam_optim,\n",
    "            loss=triplet_loss,\n",
    "        )\n",
    "        return model\n",
    "    \n",
    "    \n",
    "    os.environ['TF_CONFIG'] = json.dumps({'cluster': {'worker': [\"pipeline-worker-0:3001\",\"pipeline-worker-1:3001\",\"pipeline-worker-2:3001\"]},'task': {'type': 'worker', 'index': 2}})\n",
    "    #os.environ['TF_CONFIG'] = json.dumps({'cluster': {'worker': [\"pipeline-worker-1:3000\"]},'task': {'type': 'worker', 'index': 0}})\n",
    "\n",
    "\n",
    "    strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy(\n",
    "        tf.distribute.experimental.CollectiveCommunication.RING)\n",
    "    NUM_WORKERS = strategy.num_replicas_in_sync\n",
    "    print('=================\\r\\nWorkers: ' + str(NUM_WORKERS) + '\\r\\n=================\\r\\n')\n",
    "    #learn_rate = 0.02 + NUM_WORKERS *2\n",
    "    #learn_rate = 0.5 + NUM_WORKERS * 8\n",
    "    #learn_rate = 5 + NUM_WORKERS * 15\n",
    "    learn_rate = 0.00001 + NUM_WORKERS * 0.0000016\n",
    "    #learn_rate = 20 + NUM_WORKERS * 8\n",
    "    adam_optim = tf.keras.optimizers.Adam(lr=learn_rate)\n",
    "    batch_size = 32* NUM_WORKERS\n",
    "    model_path='/persist-log/test_model_0523.h5'\n",
    "    print(model_path)\n",
    "    callbacks = [tf.keras.callbacks.ModelCheckpoint(model_path, save_weights_only=True, verbose=1)]\n",
    "    #X_train=np.array(X_train)\n",
    "    #print(type(X_train))\n",
    "    with strategy.scope():\n",
    "        Anchor = X_train[:, 0, :].reshape(-1, img_size, img_size, channel)\n",
    "        Positive = X_train[:, 1, :].reshape(-1, img_size, img_size, channel)\n",
    "        Negative = X_train[:, 2, :].reshape(-1, img_size, img_size, channel)\n",
    "        Y_dummy = np.empty(Anchor.shape[0])\n",
    "        model = training_model((img_size, img_size, channel), FREEZE_LAYERS, facenet_weight_path)\n",
    "        \n",
    "    model.fit(x=[Anchor, Positive, Negative],\n",
    "        y=Y_dummy,\n",
    "        # Anchor_test = X_test[:, 0, :].reshape(-1, img_size, img_size, channel)\n",
    "        # Positive_test = X_test[:, 1, :].reshape(-1, img_size, img_size, channel)\n",
    "        # Negative_test = X_test[:, 2, :].reshape(-1, img_size, img_size, channel)\n",
    "        # Y_dummy = np.empty(Anchor.shape[0])\n",
    "        # Y_dummy2 = np.empty((Anchor_test.shape[0], 1))\n",
    "        # validation_data=([Anchor_test,Positive_test,Negative_test],Y_dummy2),\n",
    "        # validation_split=0.2,\n",
    "        batch_size=batch_size,  # old setting: 32\n",
    "        # steps_per_epoch=(X_train.shape[0] // batch_size) + 1,\n",
    "        epochs=10, #-------------------------------------------------------epoch\n",
    "        callbacks=callbacks\n",
    "        )  \n",
    "    \n",
    "    \n",
    "    train_time_end = time.time()\n",
    "    train_time = (train_time_end - train_time_start)/60\n",
    "    train_time_str3 = str(train_time)\n",
    "    \n",
    "    print('execution time = ',train_time_str3)\n",
    "    return [train_time_str3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "743ad8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_emb(train_time_str1:str,train_time_str2:str,train_time_str3:str)->NamedTuple('Outputs', [('block2_time_str',str)]):\n",
    "    from keras.models import load_model\n",
    "    #from tensorflow.keras.models import load_model\n",
    "    from numpy import savez_compressed, asarray, load, expand_dims\n",
    "    import sys\n",
    "    import os\n",
    "    import tensorflow as tf\n",
    "    print( sys.version)\n",
    "    sys.path.append(\"./\")\n",
    "    sys.path.append(\"/facenet-model\")\n",
    "    sys.path.append(\"/persist-log\")\n",
    "    sys.path.append(\"/configfile\")\n",
    "    from triplet_training import create_base_network\n",
    "    from config import img_size, channel, classify, FREEZE_LAYERS, facenet_weight_path, faces_data_dir\n",
    "    import time\n",
    "    import warnings\n",
    "    # ---------------------------------------\n",
    "    \n",
    "    print(\"Import Suscess...\")\n",
    "    \n",
    "    block2_start = time.time()\n",
    "\n",
    "    faces_npz = \"faces_data.npz\"\n",
    "    #facenet_model =\"facenet-model/facenet_keras.h5\"\n",
    "    \n",
    "    \n",
    "    model_path = '/persist-log/test_model_0523.h5'\n",
    "    \n",
    "    anchor_input = tf.keras.Input((img_size, img_size, channel,), name='anchor_input')\n",
    "\n",
    "    Shared_DNN = create_base_network((img_size, img_size, channel), FREEZE_LAYERS, facenet_weight_path)\n",
    "    \n",
    "    encoded_anchor = Shared_DNN(anchor_input)\n",
    "\n",
    "    model = tf.keras.Model(inputs=anchor_input, outputs=encoded_anchor)\n",
    "\n",
    "    model.load_weights(model_path)\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    def get_embedding(model, face_pixels):\n",
    "\n",
    "        # scale pixel values\n",
    "        face_pixels = face_pixels.astype('float32')\n",
    "\n",
    "        mean, std = face_pixels.mean(), face_pixels.std()\n",
    "        face_pixels = (face_pixels - mean) / std \n",
    "\n",
    "        samples = expand_dims(face_pixels, axis=0)\n",
    "\n",
    "        yhat = model.predict(samples)\n",
    "\n",
    "        return yhat[0]\n",
    "    \n",
    "    \n",
    "    data = load(faces_npz)\n",
    "    trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n",
    "    print('Loaded: ', trainX.shape, trainy.shape, testX.shape, testy.shape)\n",
    "    #print(\"The testy is :\", testy)\n",
    "    # load the facenet model\n",
    "    #model = load_model(facenet_model)\n",
    "    print('Facenet Model Loaded')\n",
    "    print(\"Embedding....\")\n",
    "    # ----------------------------------------------------------------------------------- TrainX's  Facial Image feature .\n",
    "    newTrainX = list()\n",
    "    for face_pixels in trainX:\n",
    "        embedding = get_embedding(model, face_pixels)\n",
    "        newTrainX.append(embedding)\n",
    "\n",
    "    newTrainX = asarray(newTrainX)\n",
    "    print(\"The train Image feature is:\", newTrainX)\n",
    "    print(\"The train Image feature size is:\", newTrainX.shape)\n",
    "    # ----------------------------------------------------------------------------------- TestX's  Facial Image feature .\n",
    "\n",
    "    newTestX = list()\n",
    "    for face_pixels in testX:\n",
    "        embedding = get_embedding(model, face_pixels)\n",
    "        newTestX.append(embedding)\n",
    "    newTestX = asarray(newTestX)\n",
    "    print(\"The test Image feature is:\", newTestX)\n",
    "    print(\"The test Image feature size is:\", newTestX.shape)\n",
    "    # save arrays to one file in compressed format\n",
    "    savez_compressed(\"faces_embeddings\",\n",
    "                     newTrainX, trainy, newTestX, testy)\n",
    "\n",
    "    print(\"save suscess....\")\n",
    "    \n",
    "    block2_end = time.time()\n",
    "    \n",
    "    block2_time_diff = (block2_end - block2_start)/60\n",
    "    \n",
    "    block2_time_str = str(block2_time_diff)\n",
    "\n",
    "    return[block2_time_str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fe19398",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_training(block2_time_str:str)->NamedTuple('Outputs', [('block3_time_str',str)]):\n",
    "    import pickle\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.preprocessing import Normalizer\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from numpy import load\n",
    "    import numpy as np\n",
    "    import sys\n",
    "    import os\n",
    "    from os.path import isdir\n",
    "    from os import listdir\n",
    "    import time\n",
    "    import datetime\n",
    "    from keras.models import load_model\n",
    "    import warnings\n",
    "    from sklearn.metrics import classification_report\n",
    "    print(\"import done...\")\n",
    "    block3_start = time.time()\n",
    "    #------------------------------------------------------\n",
    "    sys.path.append(\"./\")\n",
    "    \n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "    faces_embeddings = \"faces_embeddings.npz\"\n",
    "\n",
    "    svm_classifier = \"SVM_classifier.pkl\"\n",
    "    \n",
    "    data = load(faces_embeddings)\n",
    "    trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n",
    "    print('Dataset: train=%d, test=%d' % (trainX.shape[0], testX.shape[0]))\n",
    "    \n",
    "    in_encoder = Normalizer(norm='l2')\n",
    "    trainX = in_encoder.transform(trainX)\n",
    "    testX = in_encoder.transform(testX)\n",
    "    \n",
    "    out_encoder = LabelEncoder()\n",
    "    out_encoder.fit(trainy)\n",
    "    trainy = out_encoder.transform(trainy)\n",
    "    testy = out_encoder.transform(testy)\n",
    "    \n",
    "    model = SVC(kernel='linear', probability=True,C=1, max_iter=1000)\n",
    "    model.fit(trainX, trainy)\n",
    "    \n",
    "    #----------------------------------------save model\n",
    "    filename = svm_classifier\n",
    "    pickle.dump(model, open(filename, 'wb'))\n",
    "\n",
    "    yhat_train = model.predict(trainX)\n",
    "    yhat_test = model.predict(testX)\n",
    "\n",
    "    #print(yhat_train)\n",
    "    #print(yhat_test)\n",
    "    \n",
    "    #-----------------------------------------score\n",
    "    score_train = accuracy_score(trainy, yhat_train)\n",
    "    score_test = accuracy_score(testy, yhat_test)\n",
    "\n",
    "    print(classification_report(testy, yhat_test))\n",
    "\n",
    "    #----------------------------------------summarize\n",
    "    print('Accuracy: train=%.3f, test=%.3f' % (score_train * 100, score_test * 100))\n",
    "    block3_end = time.time()\n",
    "    block3_diff = (block3_end - block3_start)/60\n",
    "    block3_time_str = str(block3_diff)\n",
    "    \n",
    "    return [block3_time_str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccd7bc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dae9bcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def facial_recognition(block3_time_str:str):\n",
    "    #---------------------------------------------import facenet-model-weight-pack.\n",
    "    import sys\n",
    "    import os\n",
    "    sys.path.append(\"./\")\n",
    "    sys.path.append(\"/persist-log\")\n",
    "    sys.path.append(\"/configfile\")\n",
    "    sys.path.append(\"/templates\")\n",
    "    \n",
    "    from inception_resnet_v1 import InceptionResNetV1\n",
    "    from triplet_training import create_base_network\n",
    "    from config import img_size, channel, faces_data_dir, FREEZE_LAYERS, classify, facenet_weight_path\n",
    "    #---------------------------------------------- import main package\n",
    "    import pymongo\n",
    "    import time\n",
    "    import warnings\n",
    "    from PIL import Image\n",
    "    import numpy as np\n",
    "    from mtcnn_cv2 import MTCNN\n",
    "    #from keras.models import load_model\n",
    "    from sklearn.preprocessing import Normalizer, LabelEncoder\n",
    "    import pickle\n",
    "    from flask import Flask, render_template, Response, request, url_for, redirect\n",
    "    import cv2\n",
    "    import keras.backend.tensorflow_backend as tb\n",
    "    import tensorflow as tf\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    from threading import Thread, Lock\n",
    "    print(\"import susscess....\")\n",
    "    #---------------------------------------------class definition\n",
    "    block4_start = time.time()\n",
    "    \n",
    "    class CameraStream(object):\n",
    "        def __init__(self, src=0):\n",
    "            self.stream = cv2.VideoCapture(src)\n",
    "            (self.grabbed, self.frame) = self.stream.read()\n",
    "            self.started = False\n",
    "            self.read_lock = Lock()\n",
    "\n",
    "        def start(self):\n",
    "            if self.started:\n",
    "                print(\"already started!!\")\n",
    "                return None\n",
    "            self.started = True\n",
    "            self.thread = Thread(target=self.update, args=())\n",
    "            self.thread.start()\n",
    "            return self\n",
    "\n",
    "        def update(self):\n",
    "            while self.started:\n",
    "                (grabbed, frame) = self.stream.read()\n",
    "                self.read_lock.acquire()\n",
    "                self.grabbed, self.frame = grabbed, frame\n",
    "                self.read_lock.release()\n",
    "\n",
    "        def read(self):\n",
    "            self.read_lock.acquire()\n",
    "            frame = self.frame.copy()\n",
    "            self.read_lock.release()\n",
    "            return frame\n",
    "\n",
    "        def stop(self):\n",
    "            self.started = False\n",
    "            self.thread.join()\n",
    "\n",
    "        def __exit__(self, exc_type, exc_value, traceback):\n",
    "            self.stream.release()\n",
    "            \n",
    "            \n",
    "            \n",
    "    # ----------------------------------------------------mongodb conn.\n",
    "\n",
    "    # -----------------------------------------------------        \n",
    "    \n",
    "    cap = CameraStream().start()  \n",
    "    def getDateTime():\n",
    "        return time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "    # -----------------------------------------------------import model and classfier        \n",
    "    svm_model = pickle.load(open(\"SVM_classifier.pkl\", \"rb\"))       \n",
    "    data = np.load('faces_embeddings.npz')\n",
    "    detector = MTCNN()\n",
    "    no_results = \"unknown\"\n",
    "    \n",
    "    # ------------------------------------------------------use weight to create model \n",
    "    model_path = '/persist-log/test_model_0523.h5'\n",
    "    anchor_input = tf.keras.Input((img_size, img_size, channel,), name='anchor_input')\n",
    "\n",
    "    Shared_DNN = create_base_network((img_size, img_size, channel), FREEZE_LAYERS, facenet_weight_path)\n",
    "    encoded_anchor = Shared_DNN(anchor_input)\n",
    "\n",
    "    model = tf.keras.Model(inputs=anchor_input, outputs=encoded_anchor)\n",
    "\n",
    "    model.load_weights(model_path)\n",
    "\n",
    "    model.summary()\n",
    "    #---------------------------------------------------------- main definition\n",
    "    def face_mtcnn_extractor(frame):\n",
    "        result = detector.detect_faces(frame)\n",
    "        return result\n",
    "    \n",
    "    def face_localizer(person):\n",
    "        bounding_box = person['box']\n",
    "        x1, y1 = abs(bounding_box[0]), abs(bounding_box[1])\n",
    "        width, height = bounding_box[2], bounding_box[3]\n",
    "        x2, y2 = x1 + width, y1 + height\n",
    "        return x1, y1, x2, y2, width, height   \n",
    "            \n",
    "    def face_preprocessor(frame, x1, y1, x2, y2, required_size=(160, 160)):\n",
    "        face = frame[y1:y2, x1:x2]\n",
    "        image = Image.fromarray(face)\n",
    "        image = image.resize(required_size)\n",
    "        face_array = np.asarray(image)\n",
    "        face_pixels = face_array.astype('float32')\n",
    "        mean, std = face_pixels.mean(), face_pixels.std()\n",
    "        face_pixels = (face_pixels - mean) / std\n",
    "        samples = np.expand_dims(face_pixels, axis=0)\n",
    "        yhat = model.predict(samples)    # facenet-model\n",
    "        face_embedded = yhat[0]\n",
    "        in_encoder = Normalizer(norm='l2')\n",
    "        X = in_encoder.transform(face_embedded.reshape(1, -1))\n",
    "        return X\n",
    "    \n",
    "    def face_svm_classifier(X):\n",
    "        yhat = svm_model.predict(X)\n",
    "        label = yhat[0]\n",
    "        yhat_prob = svm_model.predict_proba(X)\n",
    "        probability = round(yhat_prob[0][label], 2)\n",
    "        trainy = data['arr_1']\n",
    "        out_encoder = LabelEncoder()\n",
    "        out_encoder.fit(trainy)\n",
    "        predicted_class_label = out_encoder.inverse_transform(yhat)\n",
    "        label = predicted_class_label[0]\n",
    "        return label, str(probability) \n",
    "    #----------------------------------------------------main code      \n",
    "    \n",
    "    app = Flask(__name__,template_folder=\"/templates\")\n",
    "    \n",
    "    @app.route('/', methods=['GET', 'POST'])\n",
    "    def index():\n",
    "        \"\"\"Video streaming home page.\"\"\"\n",
    "        if request.method == 'POST':\n",
    "            tb._SYMBOLIC_SCOPE.value = True\n",
    "            print(\"redirect\")\n",
    "            return redirect('att_list')\n",
    "        return render_template('index.html')      \n",
    "    \n",
    "    def gen_frame():\n",
    "        \"\"\"Video streaming generator function.\"\"\"\n",
    "        tb._SYMBOLIC_SCOPE.value = True\n",
    "        \n",
    "        mongo_host = \"mongodb://testUser:passwd@10.244.1.102:27017\"  # uri\n",
    "        dbName = \"db1\"\n",
    "        collectionName = \"Attendence\"\n",
    "\n",
    "        myclient = pymongo.MongoClient(mongo_host)  # conn\n",
    "        database = myclient[dbName]\n",
    "        collection = database[collectionName]\n",
    "        dblist = myclient.list_database_names()\n",
    "        print(\"Connection finished....\")\n",
    "        \n",
    "        \n",
    "        while cap:\n",
    "            frame = cap.read()        \n",
    "            \n",
    "            result = face_mtcnn_extractor(frame)\n",
    "            \n",
    "            if result:\n",
    "                \n",
    "                for person in result:\n",
    "                    \n",
    "                    x1, y1, x2, y2, width, height = face_localizer(person)\n",
    "                    \n",
    "                    X = face_preprocessor(frame, x1, y1, x2, y2, required_size=(160, 160))\n",
    "                    \n",
    "                    label, probability = face_svm_classifier(X)\n",
    "                    \n",
    "                    if float(probability) >= 0.8:\n",
    "                        print(\" Person : {} , Probability : {}\".format(label, probability))\n",
    "                        cv2.rectangle(frame, (x1, y1), (x2, y2),(0, 255, 0), 2, cv2.FILLED)\n",
    "                        # 6. Add the detected class label to the frame\n",
    "                        cv2.putText(frame, label+probability, (x1, y1-20),cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 1)\n",
    "                        \n",
    "                        if float(probability) > 0.9:\n",
    "                            label = str(label)\n",
    "                            # ------------------['name ', 'number']\n",
    "                            label = label.split('-')  # --------------------- split\n",
    "\n",
    "                            # -------------------string >>> list\n",
    "                            label = list(label)\n",
    "\n",
    "                            label_name = label[0]  # -------------------['name']\n",
    "\n",
    "                            label_num = label[1]  # -------------------['number'].\n",
    "                            \n",
    "                            Name = str(label_name)\n",
    "                            \n",
    "                            Number = str(label_num)\n",
    "                            \n",
    "                            Acc = float(probability)\n",
    "\n",
    "                            if dbName in dblist:\n",
    "                                \n",
    "                                mDictionary = {\"Name\": Name,\n",
    "                                               \"date\": getDateTime(), \"number\": Number, \"acc\": Acc}\n",
    "                                \n",
    "                                collection.insert_one(mDictionary)\n",
    "                                \n",
    "                                cursor = collection.distinct(\"Name\")\n",
    "\n",
    "                                for item in cursor:\n",
    "                                    \n",
    "                                    repeating = collection.find_one({\"Name\": Name})\n",
    "                                    result = collection.delete_many({\"Name\": Name})\n",
    "                                    collection.insert_one(repeating)\n",
    "                                    \n",
    "                            else:\n",
    "                                print(\"The database does not exist.\")\n",
    "                    else:\n",
    "                        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "\n",
    "                        cv2.putText(frame, no_results, (x1, y1-20),cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 1)\n",
    "    # ----------------------------------------------------\n",
    "            convert = cv2.imencode('.jpg', frame)[1].tobytes()\n",
    "            yield (b'--frame\\r\\n'\n",
    "                   b'Content-Type: image/jpeg\\r\\n\\r\\n' + convert + b'\\r\\n')  # concate frame one by one and show result        \n",
    "      \n",
    "    @app.route('/video_feed')\n",
    "    def video_feed():\n",
    "        return Response(gen_frame(),mimetype='multipart/x-mixed-replace; boundary=frame')        \n",
    "            \n",
    "            \n",
    "    @app.route('/att_list')\n",
    "    def list_attendence():\n",
    "        \n",
    "        \n",
    "        mongo_host = \"mongodb://testUser:passwd@10.244.1.102:27017\"  # uri\n",
    "        dbName = \"db1\"\n",
    "        collectionName = \"Attendence\"\n",
    "\n",
    "        myclient = pymongo.MongoClient(mongo_host)  # conn\n",
    "        database = myclient[dbName]\n",
    "        collection = database[collectionName]\n",
    "        dblist = myclient.list_database_names()\n",
    "        print(\"Connection finished....\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        users = collection.find()\n",
    "        print(users)\n",
    "\n",
    "        return render_template(\"att_list.html\", users=users)        \n",
    "            \n",
    "    if __name__ == '__main__':\n",
    "        app.run(host='0.0.0.0', threaded=True)        \n",
    "            \n",
    "            \n",
    "            \n",
    "    print(\"Suscess.....\")        \n",
    "    block4_end = time.time()  \n",
    "    block4_diff = (block4_end-block4_start)/60\n",
    "    block4_time_str = str(block4_diff)\n",
    "    \n",
    "    return[block4_time_str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db944d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Kserve_service(log_folder:str):\n",
    "    import subprocess\n",
    "    subprocess.run([\"python\", \"-m\", \"sklearnserver\", \"--http_port\", \"8081\", \"--model_dir\", \"sklearnserver/sklearnserver/example_models/pkl/model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d78533",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bca98876",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp.dsl as dsl\n",
    "import kfp.components as components\n",
    "from typing import NamedTuple\n",
    "import kfp\n",
    "from kfp import dsl\n",
    "from kfp.components import func_to_container_op, InputPath, OutputPath\n",
    "from kubernetes.client.models import V1ContainerPort\n",
    "from kubernetes import client as k8s_client\n",
    "@dsl.pipeline(\n",
    "   name='load-data',\n",
    "   description='load-data.'\n",
    ")\n",
    "\n",
    "def triplet_training_pipeline():\n",
    "\n",
    "    log_folder = '/persist-log'\n",
    "    pvc_name = \"face-detect-pvc\"\n",
    "    \n",
    "    \n",
    "    #label name\n",
    "    name=\"pod-name\"\n",
    "    value1=\"work-0\" # selector pod-name: work-1\n",
    "    value2=\"work-1\" # selector pod-name: work-2\n",
    "    value3=\"work-2\" # selector pod-name: work-3\n",
    "    \n",
    "    container_port=3000\n",
    "    \n",
    "    #select node\n",
    "    label_name=\"disktype\"\n",
    "    label_value0=\"worker-0\"\n",
    "    label_value1=\"worker-1\"   \n",
    "    label_value2=\"worker-2\"   \n",
    "    label_value3=\"worker-3\"   \n",
    "    \n",
    "\n",
    "    vop = dsl.VolumeOp(\n",
    "        name=pvc_name,\n",
    "        resource_name=\"newpvc\",\n",
    "        storage_class=\"managed-nfs-storage\",\n",
    "        size=\"20Gi\",\n",
    "        modes=dsl.VOLUME_MODE_RWM\n",
    "    )\n",
    "\n",
    "    load_data_op=func_to_container_op(                                       #output variable: runtime_string\n",
    "        func=load_data,\n",
    "        base_image=\"mike0355/face-recognition-0523:latest\",  \n",
    "    )\n",
    "    \n",
    "    convert_to_triplet_op = func_to_container_op(                                   #output variable: block2_time_str\n",
    "        func = convert_to_triplet,\n",
    "        base_image=\"mike0355/face-recognition-0523:latest\",  \n",
    "    )\n",
    "    \n",
    "    \n",
    "    \n",
    "    distributed_training_work1_op = func_to_container_op(\n",
    "        func = Distributed_training_work1,\n",
    "        base_image=\"mike0355/face-recognition-0523:latest\",\n",
    "    \n",
    "    )\n",
    "    \n",
    "    \n",
    "    distributed_training_work2_op = func_to_container_op(\n",
    "        func = Distributed_training_work2,\n",
    "        base_image=\"mike0355/face-recognition-0523:latest\",\n",
    "    \n",
    "    )\n",
    "    \n",
    "    \n",
    "    distributed_training_work3_op = func_to_container_op(\n",
    "        func = Distributed_training_work3,\n",
    "        base_image=\"mike0355/face-recognition-0523:latest\",\n",
    "    \n",
    "    )\n",
    "    \n",
    "    feature_emb_op = func_to_container_op(                                   #output variable: block2_time_str\n",
    "        func = feature_emb,\n",
    "        base_image=\"mike0355/face-recognition-0523:latest\",  \n",
    "    )\n",
    "    \n",
    "     \n",
    "    SVM_train_op = func_to_container_op(                                     #output variable: block3_time_str\n",
    "        func = SVM_training,\n",
    "        base_image=\"mike0355/face-recognition-0523:latest\", #    mike0355/facial-recognition-0520      mike0355/face-recognition:latest\n",
    "    )\n",
    "    \n",
    "    \n",
    "    facial_recog_op = func_to_container_op(                                    \n",
    "        func = facial_recognition,\n",
    "        base_image=\"mike0355/face-recognition-0523:latest\",  \n",
    "    )\n",
    "    \n",
    "    \n",
    "    #------------------------------------------------------------------------------------------------------------kserve\n",
    "    Kserve_service_op=func_to_container_op(                                      \n",
    "        func=Kserve_service,\n",
    "        base_image=\"mike0355/facial-rec-serve:latest\",  \n",
    "    )\n",
    "    \n",
    "    #--------------------------------------------------------------------task\n",
    "    load_data_task=load_data_op(log_folder).add_pvolumes({\n",
    "    log_folder:vop.volume,\n",
    "    })\n",
    "    \n",
    "    convert_to_triplet_task = convert_to_triplet_op(load_data_task.outputs['runtime_string']).add_pvolumes({log_folder:vop.volume,})\n",
    "    \n",
    "    \n",
    "    distributed_training_worker1_task=distributed_training_work1_op(convert_to_triplet_task.outputs['conv_time']).add_pvolumes({  #woker1\n",
    "        log_folder:vop.volume,\n",
    "    }).add_pod_label(name,value1).add_node_selector_constraint(label_name,label_value1).add_port(V1ContainerPort(container_port=3001,host_port=3001))\n",
    "    \n",
    "    \n",
    "    distributed_training_worker2_task=distributed_training_work2_op(convert_to_triplet_task.outputs['conv_time']).add_pvolumes({  #woker2\n",
    "        log_folder:vop.volume,\n",
    "    }).add_pod_label(name,value2).add_node_selector_constraint(label_name,label_value2).add_port(V1ContainerPort(container_port=3001,host_port=3001))\n",
    "    \n",
    "    \n",
    "    distributed_training_worker3_task=distributed_training_work3_op(convert_to_triplet_task.outputs['conv_time']).add_pvolumes({  #woker3\n",
    "        log_folder:vop.volume,\n",
    "    }).add_pod_label(name,value3).add_node_selector_constraint(label_name,label_value3).add_port(V1ContainerPort(container_port=3001,host_port=3001))\n",
    "    \n",
    "    \n",
    "    feature_emb_task = feature_emb_op(distributed_training_worker1_task.outputs['train_time_str1'],distributed_training_worker2_task.outputs['train_time_str2'],distributed_training_worker3_task.outputs['train_time_str3']).add_pvolumes({log_folder:vop.volume,})\n",
    "    \n",
    "    SVM_train_task =  SVM_train_op(feature_emb_task.outputs['block2_time_str']).add_pvolumes({log_folder:vop.volume,})\n",
    "    \n",
    "    #kserve_test_task = Kserve_test_op(SVM_train_task.outputs['block3_time_str']).add_pvolumes({log_folder:vop.volume,})\n",
    "    \n",
    "    facial_recog_task =  facial_recog_op(SVM_train_task.outputs['block3_time_str']).add_node_selector_constraint(label_name,label_value0).add_pvolumes({log_folder:vop.volume,}).container.set_security_context(k8s_client.V1SecurityContext(privileged = True))\n",
    "    \n",
    "    kserve_task = Kserve_service_op(SVM_train_task.outputs['block3_time_str']).add_pvolumes({log_folder:vop.volume,})\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4054a82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfp.compiler.Compiler().compile(triplet_training_pipeline, 'facial-final-serve-0525.yaml')\n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6e157a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38714428",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
